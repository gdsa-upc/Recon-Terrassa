{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Importem les llibreries numpy, time(per calcula el temps que es triga en realitza una funció) i el fitxer de configuració params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "sys.path.insert(0,'C:\\Users\\Albert\\UPC\\\\5Q\\GDSA\\Recon-Terrassa\\Projecte')\n",
    "from src.params import get_params\n",
    "#Executem la funció de configuració, que retorna un diccionari amb els valors de configuració.\n",
    "params = get_params()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Mostrem alguns d'aquets parametres de configuració, nombre de clusters, tipus de descriptor, el detector de punts clau, el redimensionament d'imatge que utilitzem (params['max_size'] es l'amplada màxima que pot tenir una imatge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 1024\n",
      "Descriptor type: SIFT\n",
      "Keypoint detector: SIFT\n",
      "Resize dimension: 300\n"
     ]
    }
   ],
   "source": [
    "print \"Number of clusters:\", params['descriptor_size']\n",
    "print \"Descriptor type:\",params['descriptor_type']\n",
    "print \"Keypoint detector:\", params['keypoint_type']\n",
    "print \"Resize dimension:\", params['max_size']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Importem la funció get_features amb la cual s'extrauen els descriptors, els punts claus de cada imatge i es monta el Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import src.get_features as GF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Posem el valor params['split'] en mode train, per extraure els descriptors nomes de les imatges d'entranament de la BBDD. Cridem la funció time() per iniciar el contador de temps, que una vegada acabada la funció es pausara i mostrarem el valor. La funció get_features redimencióna la imatge, extreu els descriptors de cada imatge, que están guardats en X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Time elapsed: 142.716999769\n",
      "(216874L, 128L)\n"
     ]
    }
   ],
   "source": [
    "params['split'] = 'train'\n",
    "\n",
    "t = time.time()\n",
    "X, pca, scaler = GF.stack_features(params)\n",
    "\n",
    "print \"Done. Time elapsed:\", time.time() - t\n",
    "print np.shape(X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Ara que ja tenim la funció d'entranament és hora d'entrenar el codebook. S'ha utilitzat MiniBatchKmeans en lloc d'utilitzar la classe KMeans de scikit-learn. Ja que aquesta va molt més rapid quan s'ha de calcular grans quantitats de dades(>10.000).\n",
    "La funció train_codebook guarda en el nostre disc un fitxer amb el model dels clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Time elapsed: 44.9649999142\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "GF.train_codebook(params,X)\n",
    "\n",
    "print \"Done. Time elapsed:\", time.time() - t"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Ara que ja tenim el Codebook, podem calcular les assignacións per cada imatge i finalment monta el nostre Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Time elapsed for training set: 143.24000001\n",
      "Done. Time elapsed for validation set: 63.9219999313\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "GF.get_features(params)\n",
    "\n",
    "print \"Done. Time elapsed for training set:\", time.time() - t\n",
    "# Switch to validation set\n",
    "params['split'] = 'val'\n",
    "\n",
    "t = time.time()\n",
    "# Run again\n",
    "GF.get_features(params)\n",
    "\n",
    "print \"Done. Time elapsed for validation set:\", time.time() - t"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Ara que ja tenim els descriptors Bag of Features de cada imatge, tant de les imatges de test com les de validació. Ara és hora de trobar les distancies entre els descriptors de les imatges de validació contra totes les imatges d'entranament. Aquestes distancies es guarden a una llista que es ordenada. I aquesta lliste ordenada et dona el ranking de similitud entre imatges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.rank import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Time elapsed: 2.29299998283\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "rank(params)\n",
    "\n",
    "print \"Done. Time elapsed:\", time.time() - t"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Ja tenim tots els ranking guardats en el disc, es hora d'avaluar-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import src.eval_rankings as ER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c0355d553a81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0map_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_rankings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Albert\\UPC\\5Q\\GDSA\\Recon-Terrassa\\Projecte\\src\\eval_rankings.py\u001b[0m in \u001b[0;36meval_rankings\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[1;31m# Get the hit & miss list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m             \u001b[0mrelnotrel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_hitandmiss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mranking\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquery_class\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mannotation_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;31m# Calculate average precision of the list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Albert\\UPC\\5Q\\GDSA\\Recon-Terrassa\\Projecte\\src\\eval_rankings.py\u001b[0m in \u001b[0;36mget_hitandmiss\u001b[1;34m(ranking, query_class, annotation_train)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;31m# Get its class from the training annotations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mi_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotation_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mannotation_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ImageID'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ClassID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;31m# And if it matches the query class...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "ap_list, dict_ = ER.eval_rankings(params)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#En aquest punt, ens em trobat amb aquest error, i ja no sabem com continuar. Ara vindria la part d'evaluació del ranking."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
